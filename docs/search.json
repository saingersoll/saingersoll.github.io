[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "My Portfolio",
    "section": "",
    "text": "Below are a collection of selected projects completed during my time in the Maters of Environmental Data Science (MEDS) program at the Bren School of Environmental Science & Management, University of California, Santa Barbara (2023-2024)."
  },
  {
    "objectID": "posts.html#welcome",
    "href": "posts.html#welcome",
    "title": "My Portfolio",
    "section": "",
    "text": "Below are a collection of selected projects completed during my time in the Maters of Environmental Data Science (MEDS) program at the Bren School of Environmental Science & Management, University of California, Santa Barbara (2023-2024)."
  },
  {
    "objectID": "scratch/ideas.html",
    "href": "scratch/ideas.html",
    "title": "",
    "section": "",
    "text": "A couple of gal pals going to see Steve Lacy! Date: May 2023.\n\n Back to top"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Sofia Ingersoll",
    "section": "",
    "text": "I am an environmental data scientist devoted to finding evidenced-based solutions to drive informed action and pave the way to a more sustainable future. I aim to bridge the understanding gap between researchers, policymakers, NPOs, private industries, and the public by delivering information in an engaging and accessible way.\nI was recently contracted as the Machine Learning Data Engineer and Geospatial Data Analyst for the Los Angeles County Ecological Conservation Project at NASA’s Jet Propulsion Laboratory. For this project I will have the unique opportunity to actively contribute to a forward-thinking project geared towards climate adaptation and local resiliency. I have a learned experience developing geospatial workflows for a variety of geo-data types. As well as a foundational understanding of working with machine learning in tandem with satellite and remote sensing materials, both of which I am excited to utilize. My interests lie in strengthening climate adaptation and resilience in vulnerable communities by supporting clean energy, resource management, extreme hazard preparation/recovery, and pollution mitigation projects. After my time at NASA JPL, I hope to continue participating in projects that elicit real and meaningful change."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Sofia Ingersoll",
    "section": "Experience",
    "text": "Experience\n Machine Learning Data Engineer & GIS Analyst | Expected 6/25 - 8/25 |\nNASA DEVELOP Analytical Mechanics Associate @ Jet Propulsion Laboratory | Pasadena, CA | Los Angeles County Ecological Conservation Project: Mapping and Identifying the Health of Urban Oak Trees in Los Angeles County\n Project Lead & Geospatial Data Analyst | 1/25 - 4/25 |\nNASA DEVELOP Analytical Mechanics Associate @ Jet Propulsion Laboratory | Pasadena, CA | San Bernardino Wildland Fires Project: Assessing the Conditions of Pre-Fire and Post-Fire Vegetation in San Bernardino California with NASA Earth Observations\n Environmental Data Scientist | 10/23 - 10/24 |\nThe 2035 Initiative, UCSB | Goleta, CA\n Master’s Capstone Lead Data Engineer & Comms Manager | 1/24 - 6/24 |\nNational Center for Atmospheric Research Climate & Global Dynamics | Goleta, CA\nUnderstanding the Influence of Parameter Value Uncertainty on Climate Model Output: Developing an Interactive Dashboard\n Environmental Data Analyst | 12/22 - 6/23 |\nUCSD Department of Analytical and Atmospheric Chemistry | La Jolla, CA\nMeasuring Airborne Toxics and Determining Oceanic Relationships (MATADOR)\n Investment Specialist | 7/19 - 8/20 |\nKeller Williams Realty, Inc. Partnered with Big H Homes | Westlake Village CA"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Sofia Ingersoll",
    "section": "Education",
    "text": "Education\n Master of Environmental Data Science | June 2024\nBren School of Environmental Science & Management, UCSB | Goleta, CA\n B.S. in Chemistry | June 2023\nUniversity of California San Diego - Earl Warren College | La Jolla, CA\n A.S. in Mathematics, Physics, Natural Sciences, and Chemistry | May 2021\nMoorpark College | Moorpark, CA"
  },
  {
    "objectID": "get_in_touch.html",
    "href": "get_in_touch.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "posts/2023-12-14_SDS_Wind_Infrastructure/SDS_Wind_Infrastructure.html#interpretation-and-social-psychology",
    "href": "posts/2023-12-14_SDS_Wind_Infrastructure/SDS_Wind_Infrastructure.html#interpretation-and-social-psychology",
    "title": "Spatially Distorted Signaling: How Opinions Against Wind Infrastructure Delay Our Transition to Renewable Energy",
    "section": "Interpretation and Social Psychology",
    "text": "Interpretation and Social Psychology\n\nResources and Political Mobilization\n\nHigher Income Brackets: Wealthier areas may exert more influence on energy policies due to their resources, potentially impacting local energy investments.\nLower Income Brackets: Individuals in lower income brackets may have less influence and lower advocacy for wind infrastructure.\n\n\n\nDonations and Lobbying\n\nFinancial Influence: Higher-income areas may use their financial resources to affect energy policy decisions, potentially hindering wind infrastructure development.\n\n\n\nInfluence of Socioeconomic Status\n\nEconomic Power: Areas with higher incomes might prioritize different types of energy investments based on their resources and political connections.\n\n\n\nOur Findings\nOur analysis of wind plant activity using logistic regression models has provided valuable insights into the factors influencing the presence of operational wind plants.\n\nMain Takeaways\nPopulation Density:\nA unit increase in population density is associated with a slight increase in the odds of having an operational wind plant. This suggests that areas with higher population densities are marginally more likely to host wind plants. Areas with higher population density often have increased energy consumption due to higher demand for residential, commercial, and industrial energy (Gillingham, Stock, 2018). This increased demand may drive investment in energy infrastructure, including renewable sources such as wind power (Lund, Mathiesen, 2009). Therein, as urbanization and population density increase, it becomes increasingly feasible and advantageous for these areas to invest in and support wind energy projects.\nMedian Income:\nAn increase in median income is linked to a decrease in the odds of having an operational wind plant. Higher income areas show a lower likelihood of wind plant activity, potentially due to different local priorities or economic factors. Previous studies have found that wealthier communities often have different priorities or face different economic constraints, which can affect their engagement with renewable energy projects (Stokes & Breetz, 2018). Higher-income areas may have more access to alternative energy solutions or face less immediate pressure to implement wind infrastructure. Wealthier communities may prioritize different types of renewable energy projects based on their specific economic and environmental goals. They may invest in more adaptable or luxury technologies rather than large-scale wind projects (Wolsink, 2007). Overall, this suggests that socioeconomic factors play a significant role in shaping the types of renewable energy projects that are pursued and highlights the need for tailored strategies to address diverse community priorities in renewable energy planning.\nAnti-Wind Infrastructure Opinion:\nPublic opposition is an influencing factor in the siting and development of wind energy projects. Areas with higher opposition to wind infrastructure are less likely to have operational wind plants. Community opposition is a well-documented barrier to wind energy deployment, local resistance can severely impact the implementation of wind energy projects (Krohn & Damborg, 1999). This is supported by other studies that show community attitudes play a crucial role in the success of wind projects, with higher opposition correlating with reduced likelihood of project success (Wolsink, 2007). Therefore, addressing and mitigating local resistance is essential for enhancing the feasibility and acceptance of wind energy initiatives.\nModel Performance:\nP-Values: The p-values for the majority of the coefficients in our models were above the significance level of 0.05. This indicates that while our models show some trends, the results are not statistically significant enough to make strong conclusions. The lack of significance suggests that there may be insufficient evidence to definitively assess the impact of these variables on wind plant activity.However, the intercept provided a baseline log-odds of having an operational wind plant fell within the range of approximately 60% for observations in this data set. The gaps within the data for areas without operating wind plants result in heavy bias towards operating wind plants.\n\n\nFuture Works Considerations\nIf given the opportunity, I would expand the dataset to include any more possible non-operational wind plants and explore in greater detail how exogenous our variables are and determine which values are likely interacting, to produce the best model fit. By expanding the dataset and refining the model, we can better understand the dynamics influencing the operational status of wind plants and make more informed conclusions. Additionally, I would bolster this analysis by identifying and including relevant variables to address the omitted variables bias present in this statistical exploration.\n\n\n\nCitations\n\nStokes, Leah C., et al. “Prevalence and Predictors of Wind Energy Opposition in North America.” Proceedings of the National Academy of Sciences, vol. 120, no. 40, Sept. 2023, doi:10.1073/pnas.2302313120.\nStoke, L. C. “Front Matter.” American Journal of Political Science, vol. 60, no. 4, 2016. JSTOR, http://www.jstor.org/stable/24877456. Accessed 26 October. 2023\nKahn, M. E. (2007). Green Cities: Urban Growth and the Environment. Brookings Institution Press.\nMcCright, A. M., & Dunlap, R. E. (2011). The Politicization of Climate Change and Polarization in the American Public’s Views of Global Warming. Society & Natural Resources, 24(5), 398-413.\nVerba, S., Schlozman, K. L., & Brady, H. E. (1995). Voice and Equality: Civic Voluntarism in American Politics. Harvard University Press.\nHertel, T. W., & Tsigas, M. E. (2002). The Role of Political Lobbying and Financial Contributions in Policy Making. In Public Policy Analysis (pp. 67-90). Routledge.\nKirschen, D. S., & Strbac, G. (2004). Fundamentals of Power System Economics. Wiley.\nGillingham, K., & Stock, J. H. (2018). The Cost of Reducing Greenhouse Gas Emissions. Journal of Economic Perspectives, 32(4), 169-190. doi:10.1257/jep.32.4.169\nLund, H., & Mathiesen, B. V. (2009). Energy system analysis of 100% renewable energy systems: The case of Denmark in years 2030 and 2050. Energy, 34(5), 524-532. doi:10.1016/j.energy.2008.10.009\nKrohn, S., & Damborg, S. (1999). Public attitudes towards wind power. Renewable Energy, 16(1), 954-960. doi:10.1016/S0960-1481(98)00339-5\nWolsink, M. (2007). Wind power implementation: The nature of public beliefs and the social acceptance of renewable energy. Renewable and Sustainable Energy Reviews, 11(6), 1586-1603. doi:10.1016/j.rser.2005.10.001\nStokes, L. C., & Breetz, H. L. (2018). Public opinion and wind energy: The impact of socio-economic factors on policy support. Environmental Politics, 27(1), 1-22. doi:10.1080/09644016.2017.1387160"
  },
  {
    "objectID": "posts/2024-12-30_Capstone/creating_a_webtool_for_climate_scientists.html",
    "href": "posts/2024-12-30_Capstone/creating_a_webtool_for_climate_scientists.html",
    "title": "Creating a Climate Modeling Web Tool for NCAR Climate & Global Dynamics Lab",
    "section": "",
    "text": "☞ GitHub Organization | Technical Documentation | Public Presentation | Data Repository\n\n Figure 1: The Gaia Future Team. Affiliations: The Bren School of Environmental Science & Management, UCSB; National Center for Atmospheric Research Climate & Global Dynamics Lab (“NCAR CGD”); National Center for Ecological Analysis and Synthesis (“NCEAS”).\n\n** Note: For the less scientifically inclined, this document may contain some unfamiliar terms. I am providing a glossary to assist, these words will be underlined throughout the text with pop-up definitions. **\n\n\nUnderstanding Climate Models\n\n\n\nFigure 2: Defining what a climate model is and its components: input parameter and climate variable output.\n\nClimate models are one of the most frequently utilized tools in climate science. In the most simple terms, they employ complex mathematics to simulate different scenarios on Earth (NOAA, 2014). They provide predictive insights into what the future may hold and are a powerful tool used to understand and mitigate potential climate hazards.\n\n\nFigure 3: Timeline of land surface categories introduction into climate modeling system (Fisher, Koven, 2020).\n\nThere are several components of Earth’s systems to consider when modeling. On the right, we can see the rapid evolution of land surface modeling since the early 70s (Fisher, Koven, 2020). Over the last decade more than a handful of categories entered the world of climate modeling. For each of these model categories, there are a handful of input parameters (e.g. soil texture) and predicted climate variable outputs (e.g. surface temperature).\n\n\nFigure 4: Utilizing the example of soil texture, a parameter with a wide range of varieties available on Earth (e.g. sand vs waterlogged soil), to explain how a predicted climate variable such as surface temperature will vary significantly depending on the input parameter value.\n\nDue to the high variability in Earth’s biomes, there is inherent uncertainty when modeling climate predictions (Navarro, 2024). To more accurately calibrate climate models and optimize their predictive accuracy, the values assigned to input parameters require evaluation and assessment. In order to do so, climate scientists must overcome the difficulties of interpreting the large volumes of convoluted predictions.\n\nAbout NCAR Climate & Global Dynamics Lab\n\n\nClimate Modeling Experiment: Parameter Perturbation Experiments (“PPE”)\nOur team’s client, NCAR CGD is an Earth system science research center sponsored by the National Science Foundation. Their research aims to increase our understanding of climate variability and climate change. Towards the outset of the MEDS program, myself and a colleague met with a member of the CGD team to discuss a recent experiment their team had conducted, the Parameter Perturbation Experiment (“PPE”). Their experiment generated a total of 10 terabytes of data. It utilized the Community Land Model version 5 (“CLM5”), the land component of the Community Earth System Model version 2 (CESM2), and consisted of two methods. Our project focused on the Latin Hypercube (“LHC”) approach.\n\n\n\nFigure 5: When imagining the method described below, it’s useful to envision a dashboard with several turning knobs input parameter for each scenario to predict climate variable. Art by Agor2012.\n\n\n\n\nLatin Hypercube (LHC)\nThe Latin Hypercube experiment attains in reflecting the natural chaos of the world by allowing for dynamic changes throughout all input parameters for each simulation. No two parameters contain the same input value (Eidhammer, et. al., 2024). However, they all fall within a standardized range of 0 and 1 and are an estimation of accepted values found in nature. In reality, these parameters are ever-changing, making the LHC approach a closer representation to Earth’s systems. Be that as it may, it is just as difficult to interpret. \n\n\nThe Issues\n\nThe raw data and metadata documentation was not easily accessible.\nRequired additional wrangling and visualizations in order to interpret simulation predictions.\nLacked prediction uncertainty measurements, thus inhibiting model calibration.\n\n\n\nOur Goal\nOur mission was to create a web tool that invites discovery, discussion, and innovation amongst climate scientists utilizing the PPE LHC data. Our team sought to deliver:\n\nDescriptive metadata describing the model components and their associated Earth system category. \nAdaptive machine learning tools and visualization to display a 1:1 input parameter-climate variable relationship with 3 st. dev. of associated uncertainty.\nSensitivity visualization capable of ranking each input parameters contribution to the climate variable prediction, alongside a cross validation accuracy plot. \nOrganized and optimized internal data archival system that grows with new user queries.\nA containerized web tool compatible with continuous integration. \n\n\n\nFigure 6: This is our web tool. On the left is an overview of the landing page with a prediction. The right displays the metadata associated with the categorized input parameters.\n\n\n\nOur Approach\n\n\nCreate a robust file processing system: specifications include time range, parameter, and climate variable.\nDevelop an flexible machine learning emulator that can capture the complexity in the data and individually isolate a 1-to-1 parameter-climate variable relationship with embedded uncertainty and accuracy testing.\nProvide informative visualizations packaged in a user-friendly web application that requires minimal upkeep. \n\n\nFigure 7: Reproducible workflow for NCAR CDG’s PPE data visualization and interpretation.\n\n\nTangible Solutions\n\n\nOptimized Computing & Data Archival Tactics\n\n\nFigure 8: Data wrangling workflow, from raw PPE data into tidy data for machine learning analysis. Blue represents the user selected climate variable that was simulated and orange is the collection of accepted parameter values.\n\nWe wanted to make the information relevant to a user’s interest, so options to select a timeline, input parameter, and climate variable were essential. For the query of interest, appropriate weights to the temporal dimension were applied, so that time reflected calendar months accurately. Additionally, spatial weights for grid cells were assigned according to respective land area. Once wrangled, these data sets were ready for machine learning analysis.\nTo reduce the computational burden and carbon consumption associated with our web tool, we employed the unique package, pickle. Similar to the traditional idea of preserving, ‘pickling’ is a systematic approach to storing data long-term in a low storage way. The phrase is coined by the package provider. ‘Pickling’ processes high volumes of data files using serialization for fast storage and loading (pickle, 2024). In contrast, ‘unpickling’ undoes this process for quick predictions and visualizations. Whenever applicable, our application stores and retrieves data in lieu of repeating tabulations. As the web tool is more heavily used, the data archive will increase and the overall computational workload will be reduced overtime. \n\n\nMachine Learning Emulator & Data Visualizations\n*Bare with me, we are entering the densest sections, they contain pertinent details about our model components.*\n\n\nGaussian Process Regression + Uncertainty\n\n\nFigure 9: ‘Black box’ machine learning workflow displaying the preliminary data visualization outputs.\n\nThe objective when creating our tool was to provide climate scientists visual insights into how interesting certain parameter-climate variable relationships are over time with a defined level of confidence. To interpret the complex PPE data, a machine learning tool with flexible capabilities had to be built to provide insights into relationships and predictive uncertainty. The specific ML tool employed in this case was Gaussian Process Regression (“GPR”). \nIn layman’s terms, GPR can isolate individual parameters and determine their relationship with a predicted climate variable and the associated uncertainty (Görtler, et al., 2019). It is easiest to consider the GPR emulator as a ‘black box’. The tool itself simplifies the heavy lifting of the scientist by computing a surplus of predictions for a scenario without a defined statistical equation (Rasmussen, Williams, 2006). It emulates the climate scenario as described by the PPE data. The tool applies Bayesian statistics to average the predictions and provide 3 standard deviations of uncertainty. This can be seen above in the regression plot on the left side.\n\n\nFAST: Fourier Amplitude Sensitivity Transformation + Cross Validation Accuracy Testing\nThis following feature will allow climate scientists the ability to identify major contributors to specific climate events. Leveraging our machine learning tool, a sensitivity analysis feature for predictions was developed using a method called FAST, Fourier Amplitude Sensitivity Transformation. In the simplest terms, FAST  can isolate each parameter and rank them according to their relative influence on a predicted climate variable. Mathematically, FAST conducts a sensitivity analysis by decomposing the variance of the involved components and assigning it accordingly to parameters for a predicted scenario (Fang, Gertner, et. al., 2003). To assess the accuracy of the GPR and FAST predictions, a cross validation test was conducted for each simulation, plotted, and paired with the associated R² value. This is the inset plot seen above on the right.\n\n\nContainerized Web Application with Continuous Integration\n\n\nFigure 10: Workflow to describe the back-end workflow of the dashboard operating system.\n\nOur team prepared a maintenance plan for our web tool hand-off. All essential software is embedded within our product. We used the Docker approach to do so and containerize our web app. This prevents any package updates made in the future from breaking our code. The deliverable is currently in the hands of the NCAR Software Team and is awaiting publication. Its future application will lead to climate model calibrations that will contribute upstream to the Coupled Model Intercomparison Project (“CMIP”) provided by the Intergovernmental Panel on Climate Change (“IPCC”).\n\n\nAcknowledgements\nThe author of this blog post would like to say a special thank you to the cross-country team that supported our project:\nNational Center for Atmospheric Research: Dr. Daniel Kennedy, Project Scientist; Nick Cote, Software Engineer;\nBren School of Environmental Science & Management: Dr. Carmen Galaz García, Assistant Teaching Professor; Dr. Satie Airamé, Assistant Dean; Emily Case, Capstone Project Coordinator;\nColumbia University: Dr. Linnia Hawkins, Associate Research Scientist\n\n\nGlossary\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n10 terabytes of data: A large amount of digital information equivalent to approximately 10,000 gigabytes. Often used to store or analyze extensive datasets.\nAccuracy: A measure of how close a predicted value is to the true value, often expressed as a percentage.\nBayesian statistics: A statistical approach that uses probability distributions to represent uncertainty in estimates and incorporates prior knowledge.\nBlack box: A system or model where the internal workings are not visible or understood, but inputs and outputs are observed.\nClimate variable: A measurable factor related to climate, such as temperature, precipitation, or wind speed, often used as a predicted output in models.\nCommunity Earth System Model version 2 (CESM2): A comprehensive climate model used for simulating Earth’s climate system and its components.\nContainerized web tool: A web-based application deployed within a container, which ensures consistency and scalability across computing environments.\nContinuous integration: A software development practice where code changes are automatically tested and integrated into a shared repository to ensure stability.\nCoupled Model Intercomparison Project (“CMIP”): A collaborative framework designed to improve climate models and compare their predictions on a global scale.\nCross Validation Test: A statistical method used to evaluate a model’s predictive performance by partitioning data into training and testing subsets.\nDefined level of confidence: A quantified level of certainty, often expressed as a percentage, indicating the likelihood that a result is accurate.\nFourier Amplitude Sensitivity Transformation (“FAST”): A technique used to assess the sensitivity of a model’s output to its input parameters.\nGaussian Process Regression (GPR): A non-parametric, probabilistic model used in machine learning to predict outputs and quantify uncertainty.\nGridcell; A single unit or cell within a spatial grid used in climate modeling, representing a defined area of Earth’s surface.\nInset plot: A smaller plot embedded within a larger plot to provide additional detail or context.\nIntergovernmental Panel on Climate Change (“IPCC”): An international organization that assesses scientific knowledge on climate change to guide policy decisions.\nLayman’s terms: Simple, non-technical language used to explain complex concepts.\nMachine learning emulator: A computational model that mimics the behavior of a more complex system to save time and resources.\nMetadata: Information that describes other data, such as its source, format, or context, to improve usability and understanding.\nParameter: A variable within a model or equation that influences its output.\nPredictive Uncertainty: The range of possible values for a prediction, reflecting the model’s uncertainty.\nQuery: A request for specific information from a database or dataset.\nR² value: A statistical measure of how well a model’s predictions match observed data, ranging from 0 (no fit) to 1 (perfect fit).\nRaw data: Unprocessed data collected directly from sources, often requiring cleaning and formatting.\nRegression plot: A graph that visualizes the relationship between independent and dependent variables, often used in statistical modeling.\nSensitivity analysis: A technique used to determine how different input variables affect a model’s output.\nSt. dev. | standard deviation: A measure of data spread that quantifies the variation around the mean.\nStatistical equation: A mathematical formula that represents relationships between variables in a dataset.\nSpatial weight: A factor used in spatial analysis to account for the influence of one area on another.\nTemporal dimension: The time-based aspect of data or models, often used to track changes over time.\nVariance: A statistical measure that describes the spread of data points around the mean.\nUncertainty measurements: Quantitative estimates of the doubt associated with a model’s predictions. Wrangling The process of cleaning, transforming, and organizing raw data for analysis.\n\n\n\n\nReferences\n\nAgor. “Set of Control Panel Elements for Spacecraft, Technical Knobs.” Shutterstock, 2012,https://www.shutterstock.com/image-vector/set-control-panel-elements-spacecraft-technical-1537154573. Accessed 03 Dec. 2024.\nDagon, Katie, and Daniel Kennedy. Parameter Perturbation Experiment (PPE). National Center for Atmospheric Research, 2023,https://www.cgd.ucar.edu/events/seminar/2023/katie-dagon-and-daniel-kennedy-132940. Accessed 03 Mar. 2024.\nEidhammer, Trude & Gettelman, Andrew & Thayer-Calder, Katherine & Watson-Parris, Duncan & Elsaesser, Gregory & Morrison, Hugh & van Lier-Walqui, Marcus & Song, Ci & Mccoy, Daniel. (2024). An extensible perturbed parameter ensemble for the Community Atmosphere Model version 6. Geoscientific Model Development. 17. 7835-7853. 10.5194/gmd-17-7835-2024. Accessed 03 Dec. 2024.\nFang, S., Gertner, G.Z., Shinkareva, S. et al. Improved generalized Fourier amplitude sensitivity test (FAST) for model assessment. Statistics and Computing 13, 221–226 (2003). https://doi.org/10.1023/A:1024266632666\nGörtler, et al., “A Visual Exploration of Gaussian Processes”, Distill (2019), https://distill.pub/2019/visual-exploration-gaussian-processes/ . Accessed 03 Dec. 2024.\nIntergovernmental Panel on Climate Change. About the IPCC. IPCC,https://www.ipcc.ch/about/. Accessed 3 March 2024.\nLawrence, David M., et al. “The Community Land Model Version 5: Description of New Features, Benchmarking, and Impact of Forcing Uncertainty.” Journal of Advances in Modeling Earth Systems, vol. 11, no. 12, 2019, pp. 4245–4287, https://doi.org/10.1029/2018MS001583. Accessed 30 Dec. 2024.\nNational Center for Atmospheric Research, Climate and Global Dynamics Division. About CGD. University Corporation for Atmospheric Research,https://www.cgd.ucar.edu/. Accessed 31 Dec. 2024.\nNational Center for Atmospheric Research. Community Earth System Model Version 2 (CESM2). University Corporation for Atmospheric Research,https://www.cesm.ucar.edu/models/cesm2. Accessed 30 Dec. 2024.\nNavarro, A., Lee, G., Martín, R. et al. “Uncertainties in measuring precipitation hinders precise evaluation of loss of diversity in biomes and ecotones”. npj Clim Atmos Sci 7, 35 (2024). https://doi.org/10.1038/s41612-024-00581-w Accessed 03 Dec. 2024.\nNOAA. “Climate Models.” NOAA Climate.Gov, 14 Nov. 2014, www.climate.gov/maps-data/climate-data-primer/predicting-climate/climate-models. Accessed 03 Dec. 2024.\nPickle — Python Object Serialization. Python Software Foundation,https://docs.python.org/3/library/pickle.html. Accessed 30 Dec. 2024.\nRasmussen, C. E., & Williams, C. K. I., “Gaussian Processes for Machine Learning”, MIT Press (2006). Accessed 3 March 2024\nWorld Climate Research Programme. Coupled Model Intercomparison Project (CMIP). WCRP,https://www.wcrp-climate.org/wgcm-cmip. Accessed 3 March. 2024.\n\n\n\n\n\n Back to topCitationBibTeX citation:@online{ingersoll2024,\n  author = {Ingersoll, Sofia},\n  title = {Creating a {Climate} {Modeling} {Web} {Tool} for {NCAR}\n    {Climate} \\& {Global} {Dynamics} {Lab}},\n  date = {2024-12-30},\n  url = {https://saingersoll.github.io/posts/creating_a_webtool_for_climate_scientists.html},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nIngersoll, Sofia. 2024. “Creating a Climate Modeling Web Tool for\nNCAR Climate & Global Dynamics Lab.” December 30, 2024. https://saingersoll.github.io/posts/creating_a_webtool_for_climate_scientists.html."
  },
  {
    "objectID": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html",
    "href": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html",
    "title": "Investigation on the Thomas Fire Impacts in Santa Barbara County, CA (2017 - 2018)",
    "section": "",
    "text": "Google earth V 6.2.2.6613. (December 13, 2017). Santa Barbara, United States. 34.6099° N, 120.0665° W, Eye alt 13.72 feet. DigitalGlobe 2020. http://www.earth.google.com [December 12, 2023].\n\n\n\nOn December 4, 2017, the Thomas Fire in Santa Barbara County. began to sweep throughout Ventura and Santa Barbara County, CA. For 40 days, a devistating total of 281,893 acres were consumed; destroying 1,063 structures and claiming two casualties (one civilian and one firefighter). Investigations have found that this wildfire was the result of a “line slap,” shared between Southern California Edison (“SCE”) powerlines during a high wind event that sparked hot materials to ignite a nearby fuel bed (Ventura County Fire Department). As of 2019, SCE agreed to a $360 million settlement to address the conglomorate negative impacts caused by the Thomas Fire, Woolsey Fire, and Koeningstein Fire. As well as, the ripple effect of the Thomas Fire, which was especially felt by community members in January of 2018 when 23 lives were claimed from a debris flow in Montecito (Wildfire Today, California Govenor’s Office of Emergency Services).\n\n\n\nTo get a better understanding of the initial environmental and public health impacts caused by the Thomas Fire, together, we will explore the Air Quality Index (AQI) of SB County between 2017/01 - 2018/10. We’ll quanitfy and visualize the amount of particulate matter seen in the image abouve using both the Daily AQI and the average AQI over a 5 day rolling window in units of ppm. In addition, we will gain insight into what parts of Santa Barbara County were exposed to the Thomas Fire, through the examination of burn scars using false-color imaging on Landsat 8 satellite data from the Microsoft Planetary Computer (“MPC”). We will use a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data.\n\n\n\nIn AQI the figure on the left, there is a sharp peak observed the day the Thomas Fire began (Dec. 4, 2017) that fell within the Very Unhealthy category and over a 5 day period, averaged out into the Unhealthy category. This trend can be observed at the noted location in the figure below, indicating negative public health effects on air quality resulting from the Thomas Fire. The figure on the right, displays the large parcel of Santa Barbara County that was engulfed by the fire, explaining the uptake in particulate matter observed in December of 2017. There were significant direct impacts on public health in terms of air quality as a response to this fire and this can be understood when considering the size of the burn scar seen in the figure on the right.\n\n\n\nAQI_Assessment.png\n\n\n\n\n\n\nDirectly accessing & processing MPC STAC data\nRaster analysis applying false color imagery\nTime series analysis\n\n\n\n\n\n\nThe Daily Air Quality Index (AQI) data to quantify the particulate matter released into Santa Barbara County from the fire was collected here from the US Environmental Protection Agency to visualize the rolling AQI averages between 2017 and 2018.\n\n\n\nFor our true and false color imagery, we are going to direct access Microsoft Planetary Computer Landsat Collection 2 Level-2 data. The STAC item utilized for this project is ****LE07_L2SP_042036_20171217_02_T1****. The raster data was collected on 2017-12-17.\nThis data should be used for visualization purposes only.\n\n\n\nThe shapefile of fire perimeters in California were provided by the California State Geoportal. The complete file can be accessed here.\n\n\n\n\nUS Environmental Protection Agency (2023). Daily AQI by County [Data File]. Available from https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed October 25, 2023\nMicrosoft Planetary Computer. Landsat Collection 2 Level-2 [Dataset]. Available from https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed November 28, 2023\nCalifornia Department of Forestry and Fire Protection (2023). California Fire Perimeters (all) [Data File]. Available from https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed November 28, 2023\n\n\n\n\n\n\n\nCode\n#------------------------------------\n# ----    Load the Essentials    ----\n#------------------------------------\n# Reading in libraries and functions\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nimport pystac\nimport planetary_computer\n\nimport rasterio\nimport xarray as xr\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom shapely.geometry import Polygon\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport matplotlib.patches as mpatches\n\n\n\n\n\nTo simplify our workflow, we’re going to combine the 2017 and 2018 data sets, and wrangle a single concatonated dataset.\nOnce we have one dataset, we will select our region of interest (ROI) and correct the Date dtype so it may be used as the index to calculate the average Air Quality Index over a 5 day rolling window.\n\n\nCode\n#------------------------------------\n# ----       Read & Wrangle      ----\n#------------------------------------\n# Reading in the data\naqi_17 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip')                     \naqi_18 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip') \n\n# glueing the datasets together\naqi = pd.concat([aqi_17, aqi_18])                                                                         \n#  .str.replace(' ','_') to replace the space for _\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')     \n\n# Subsetting using loc\n# selecting SB county\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara']   \n# isolating desired columns   \naqi_sb = aqi_sb.iloc[:, 4:]                               \n\n#  Datetime Indexing\n# converting the date type to datetimes64\naqi_sb.date = pd.to_datetime(aqi_sb.date)    \n # updating the index to the data column                       \naqi_sb = aqi_sb.set_index('date')                                    \n\n# Rolling Window Mean Calc\n# provides rolling window calculations of \n# the mean aqi over 5 day periods  \naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()         \n\n\n\n\nIs everything looking as we expect it to?\n\n\nCode\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# checking that dataframes joined properly and column names changed\nprint('The number of aqi observations in 2017 were:', len(aqi_17.Date))\nprint('The number of aqi observations in 2018 were:', len(aqi_18.Date))\nprint('The number of aqi observations between 2017-2018 were:', len(aqi.date))        \n\n\nThe number of aqi observations in 2017 were: 326801\nThe number of aqi observations in 2018 were: 327537\nThe number of aqi observations between 2017-2018 were: 654338\n\n\n\n\n\n\nThe visual below displays the mean AQI over a 5 day rolling window between January 2017 and October 2018. The background of the plot is color categorized according to the AQI’s six categories of concern for ppm levels. A relative trend of moderate is seen throughout the year. However,a spike in air pollutants between the months of December 2017 and January 2018 is clearly observed. The sharp initial peak observed the day the Thomas Fire began (Dec. 4, 2017) caused an inital AQI response within the Very Unhealthy category and over a 5 day period, averaged out into the Unhealthy category. This trend can be observed at the noted location in the figure below, indicating negative public health effects on air quality resulting from the Thomas Fire.\n\n\nCode\n#------------------------------------\n#  ----     Customization        ----\n#------------------------------------\n# Define AQI categories and colors\naqi_categories = {\n    'Good': (0, 50, '#00E400'),\n    'Moderate': (51, 100, '#FFFF00'),\n    'Unhealthy for Sensitive Groups': (101, 150, '#FF9933'),\n    'Unhealthy': (151, 200, '#FF0000'),\n    'Very Unhealthy': (201, 300, '#8B0000'),\n    'Hazardous': (301, 500, '#800080')\n}\n\ncolors = {'aqi':'#f69517',\n          'five_day_average':'#360F39'}\n\n\n#------------------------------------\n#  ----     Visualizing AQI      ----\n#------------------------------------\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Plot AQI categories as background colors for associated ranges\nfor category, (lower, upper, color) in aqi_categories.items():\n    ax.fill_between(aqi_sb.index, lower, upper, color=color,\n                    alpha=0.2,\n                    label=f'{category}')\n\n# Plot the AQI and 5-Day Rolling Average\naqi_sb.plot(ax=ax,\n            y=['aqi', 'five_day_average'],\n            color=colors,\n            xlabel='Date',                                                   \n            ylabel='AQI Values (ppm)',\n            ylim= (0,400),\n            legend= True\n            )\n\n# applying customizations\nax.set_title('Air Quality Index (AQI) Assessment of Santa Barbara County 2017-2018', \n             fontsize=18) \n\n# Add a legend for background colors\nbackground_legend = [Line2D([0], [0], color='#00E400', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FFFF00', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FF9933', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FF0000', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#8B0000', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#800080', lw=4, alpha=0.3)]\n\n# Add background color legend to the plot\nbackground_legend_art = ax.legend(handles=background_legend,\n                                  labels=['Good', 'Moderate',\n                                          'Unhealthy for Sensitive Groups',\n                                          'Unhealthy', 'Very Unhealthy',\n                                          'Hazardous'],\n                                  loc='upper center',\n                                  bbox_to_anchor=(0.5, 1),\n                                  ncol=3,\n                                  fontsize = 12)\n# Line color legend\nline_legend = [Line2D([0], [0], color='#f69517', lw=2),\n               Line2D([0], [0], color='#360F39', lw=2)]\n\n# Add line color legend to the plot\nline_legend_art = ax.legend(handles=line_legend,\n                            labels=['AQI', '5-Day Average'],\n                            loc='upper right',\n                            bbox_to_anchor=(0.866, 0.88),\n                            fontsize = 12)\n\n# Add both legends to the plot\nax.add_artist(background_legend_art)\nax.add_artist(line_legend_art)\n\n# Add annotation\nax.annotate(\"* This peak is a result of the \\nThomas Fire in Santa Barbara.\", \n            xy=(0.45, 0.5), # position\n            xycoords='figure fraction', \n            fontsize=12, \n            color='black') \n\n# Adjust subplot parameters to add margin space\nplt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)\n\nplt.show()\n\n\n\n\n\n\n\n\nLet’s get a full understanding of exactly how much local area was affected by the Thomas Fire by importing the fire perimeter boundary information & some super cool Landsat 2\n\n\n\n\nCode\n#------------------------------------\n# ----        Read  & Inspect     ----\n#------------------------------------\n# Reading in the data for CA fire perimeters \nca_fire = gpd.read_file(os.path.join(os.getcwd(),'..','data','California_Fire_Perimeters_1379327890478655659','California_Fire_Perimeters_(all).shp'))\n\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# Suppress warnings\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning) \n\n# Create a figure with two subplots\nfig, ax = plt.subplots(1, 2, figsize=(14, 7))\n\n# quick viuslaization of CA fire perimeters\n# yow-za! CA is so clearly shaped }:&lt;\nca_fire.plot(ax = ax[0],\n             color = '#AA4203')\nax[0].set_title('CA Fire Perimeters')\n\n\n# Subset for Thomas Fire boundary data for plotting\nthomas_fire = ca_fire.loc[(ca_fire['FIRE_NAME'] == 'THOMAS') & (ca_fire['YEAR_'] &gt;= 2017)]          \n\n\nthomas_fire.plot(ax = ax[1],\n                 color = '#AA4203')\nax[1].set_title('Thomas Fire Boundary')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nTogether, we’re going to load in Landsat data directly from the Microsoft Planetary Computer STAC and collect our desired bands (SWIR22, NIR08, Red) to create a landsat array subset.LE07_L2SP_042036_20171217_02_T1 was captured on 12/17/2017 18:36:51 UTC and will be leveraged for this project.\nIn order to create a false color image, we need to adjust the dimensions of our data to only consider x and y coordinates. Furthermore, we will need to create an array containing the false color bands we intend on utilizing for our ROI. We’ll also be correcting the CRS so we can overlay the two datasets.\n\n\nCode\n#--------------------------------------\n# ---- Pull directly from MPC STAC ----\n#--------------------------------------\n# Suppress warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)  # Suppress FutureWarnings\n\n\n# Let's pull our data fresh from the MPC STAC\n# We're also going to assign the bands we're interested in\nitem_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LE07_L2SP_042036_20171217_02_T1\"\n\n# Load the individual item metadata and sign the assets\nitem = pystac.Item.from_file(item_url)\nsigned_item = planetary_computer.sign(item)\n\n#--------------------------------------\n# ----   Collect band information  ----\n#--------------------------------------\n# Open the desired data assets\n# Short Wave Infrared (SWIR22) band\nasset_href_swir22 = signed_item.assets[\"swir22\"].href\nlandsat_swir22 = rioxr.open_rasterio(asset_href_swir22)\n\n# Near Infrared (NIR08) band\nasset_href_nir08 = signed_item.assets[\"nir08\"].href\nlandsat_nir08 = rioxr.open_rasterio(asset_href_nir08)\n\n# Red band\nasset_href_red = signed_item.assets[\"red\"].href\nlandsat_red = rioxr.open_rasterio(asset_href_red)\n\n# Green band\nasset_href_green = signed_item.assets[\"green\"].href\nlandsat_green = rioxr.open_rasterio(asset_href_green)\n\n# Blue band\nasset_href_blue = signed_item.assets[\"blue\"].href\nlandsat_blue = rioxr.open_rasterio(asset_href_blue)\n\n#--------------------------------------\n#  ----  Combine band information  ---- \n#--------------------------------------\n#--------------------------------------\n#  ----         True Color         ---- \n#--------------------------------------\n# Stack bands into a single dataset\ntrue_color = xr.concat([landsat_red, landsat_green, landsat_blue], dim='band')\n\n# Updating data for plotting\n# Original dimensions and coordinates show us that band is a dimension\n# Remove length 1 dimension (band)\ntrue_color = true_color.squeeze()\n\n# remove coordinates associated to band\ntrue_color = true_color.drop('band')\n\n#--------------------------------------\n#  ----        False Color         ---- \n#--------------------------------------\n# Note: For false-color, typically, you might use \n# a different combination (like NIR, Red, Green).\n# Adjust this based on the specific visualization you want.\nfalse_color = xr.concat([landsat_swir22, landsat_nir08, landsat_red], dim='band')\n\n# Updating data for plotting\n# Original dimensions and coordinates show us that band is a dimension\n# Remove length 1 dimension (band)\nfalse_color = false_color.squeeze()\n\n# remove coordinates associated to band\nfalse_color = false_color.drop('band')\n\n#--------------------------------------\n#  ---- Visualize band information ---- \n#--------------------------------------\n# Create a figure with two subplots\nfig, ax = plt.subplots(1, 2, figsize=(14, 7))\n\n# Plot the true and false color images\n#--------------------------------------\n#  ----     True Color Image       ---- \n#--------------------------------------\n# Plot the false color image\ntrue_color.plot.imshow(ax=ax[0],\n                        robust=True) \nax[0].set_title('True Color Landsat Image (Red, Green, Blue)')\n\n\n#--------------------------------------\n#          False Color Image\n#--------------------------------------\nfalse_color.plot.imshow(ax=ax[1],\n                        robust=True)\nax[1].set_title('False Color Landsat Image (SWIR22, NIR08, Red)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nIt looks good, let’s take a quick peak at the geospatial attr\n\n\nCode\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# Check geospatial attributes\nprint('height: ', false_color.rio.height)\nprint('width: ', false_color.rio.width, '\\n')\nprint(false_color.rio.bounds(), '\\n')\n\n# Now to update the CRS to match and check\n# Convert DataFrame to GeoDataFrame\nthomas_fire  = gpd.GeoDataFrame(thomas_fire, geometry='geometry')\n\nthomas_fire = thomas_fire.to_crs(false_color.rio.crs)                                      \n\n# Print CRS to check alignment\nprint('Thomas Fire Boundary CRS: ', thomas_fire.crs)\nprint('False Color CRS: ', false_color.rio.crs)\n\n\nheight:  7271\nwidth:  8291 \n\n(106785.0, 3725685.0, 355515.0, 3943815.0) \n\nThomas Fire Boundary CRS:  PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\nFalse Color CRS:  EPSG:32611"
  },
  {
    "objectID": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html#investigation-on-the-thomas-fire-impacts-in-santa-barbara-county-ca-2017---2018",
    "href": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html#investigation-on-the-thomas-fire-impacts-in-santa-barbara-county-ca-2017---2018",
    "title": "Investigation on the Thomas Fire Impacts in Santa Barbara County, CA (2017 - 2018)",
    "section": "",
    "text": "Google earth V 6.2.2.6613. (December 13, 2017). Santa Barbara, United States. 34.6099° N, 120.0665° W, Eye alt 13.72 feet. DigitalGlobe 2020. http://www.earth.google.com [December 12, 2023].\n\n\n\nOn December 4, 2017, the Thomas Fire in Santa Barbara County. began to sweep throughout Ventura and Santa Barbara County, CA. For 40 days, a devistating total of 281,893 acres were consumed; destroying 1,063 structures and claiming two casualties (one civilian and one firefighter). Investigations have found that this wildfire was the result of a “line slap,” shared between Southern California Edison (“SCE”) powerlines during a high wind event that sparked hot materials to ignite a nearby fuel bed (Ventura County Fire Department). As of 2019, SCE agreed to a $360 million settlement to address the conglomorate negative impacts caused by the Thomas Fire, Woolsey Fire, and Koeningstein Fire. As well as, the ripple effect of the Thomas Fire, which was especially felt by community members in January of 2018 when 23 lives were claimed from a debris flow in Montecito (Wildfire Today, California Govenor’s Office of Emergency Services).\n\n\n\nTo get a better understanding of the initial environmental and public health impacts caused by the Thomas Fire, together, we will explore the Air Quality Index (AQI) of SB County between 2017/01 - 2018/10. We’ll quanitfy and visualize the amount of particulate matter seen in the image abouve using both the Daily AQI and the average AQI over a 5 day rolling window in units of ppm. In addition, we will gain insight into what parts of Santa Barbara County were exposed to the Thomas Fire, through the examination of burn scars using false-color imaging on Landsat 8 satellite data from the Microsoft Planetary Computer (“MPC”). We will use a simplified collection of bands (red, green, blue, near-infrared and shortwave infrared) from the Landsat Collection 2 Level-2 atmosperically corrected surface reflectance data.\n\n\n\nIn AQI the figure on the left, there is a sharp peak observed the day the Thomas Fire began (Dec. 4, 2017) that fell within the Very Unhealthy category and over a 5 day period, averaged out into the Unhealthy category. This trend can be observed at the noted location in the figure below, indicating negative public health effects on air quality resulting from the Thomas Fire. The figure on the right, displays the large parcel of Santa Barbara County that was engulfed by the fire, explaining the uptake in particulate matter observed in December of 2017. There were significant direct impacts on public health in terms of air quality as a response to this fire and this can be understood when considering the size of the burn scar seen in the figure on the right.\n\n\n\nAQI_Assessment.png\n\n\n\n\n\n\nDirectly accessing & processing MPC STAC data\nRaster analysis applying false color imagery\nTime series analysis\n\n\n\n\n\n\nThe Daily Air Quality Index (AQI) data to quantify the particulate matter released into Santa Barbara County from the fire was collected here from the US Environmental Protection Agency to visualize the rolling AQI averages between 2017 and 2018.\n\n\n\nFor our true and false color imagery, we are going to direct access Microsoft Planetary Computer Landsat Collection 2 Level-2 data. The STAC item utilized for this project is ****LE07_L2SP_042036_20171217_02_T1****. The raster data was collected on 2017-12-17.\nThis data should be used for visualization purposes only.\n\n\n\nThe shapefile of fire perimeters in California were provided by the California State Geoportal. The complete file can be accessed here.\n\n\n\n\nUS Environmental Protection Agency (2023). Daily AQI by County [Data File]. Available from https://aqs.epa.gov/aqsweb/airdata/download_files.html#AQI. Accessed October 25, 2023\nMicrosoft Planetary Computer. Landsat Collection 2 Level-2 [Dataset]. Available from https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2. Accessed November 28, 2023\nCalifornia Department of Forestry and Fire Protection (2023). California Fire Perimeters (all) [Data File]. Available from https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about. Accessed November 28, 2023\n\n\n\n\n\n\n\nCode\n#------------------------------------\n# ----    Load the Essentials    ----\n#------------------------------------\n# Reading in libraries and functions\nimport os\nimport warnings\nimport numpy as np\nimport pandas as pd\n\nimport pystac\nimport planetary_computer\n\nimport rasterio\nimport xarray as xr\nimport geopandas as gpd\nimport rioxarray as rioxr\nfrom shapely.geometry import Polygon\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.lines import Line2D\nimport matplotlib.patches as mpatches\n\n\n\n\n\nTo simplify our workflow, we’re going to combine the 2017 and 2018 data sets, and wrangle a single concatonated dataset.\nOnce we have one dataset, we will select our region of interest (ROI) and correct the Date dtype so it may be used as the index to calculate the average Air Quality Index over a 5 day rolling window.\n\n\nCode\n#------------------------------------\n# ----       Read & Wrangle      ----\n#------------------------------------\n# Reading in the data\naqi_17 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2017.zip')                     \naqi_18 = pd.read_csv('https://aqs.epa.gov/aqsweb/airdata/daily_aqi_by_county_2018.zip') \n\n# glueing the datasets together\naqi = pd.concat([aqi_17, aqi_18])                                                                         \n#  .str.replace(' ','_') to replace the space for _\naqi.columns = aqi.columns.str.lower().str.replace(' ','_')     \n\n# Subsetting using loc\n# selecting SB county\naqi_sb = aqi.loc[aqi.county_name == 'Santa Barbara']   \n# isolating desired columns   \naqi_sb = aqi_sb.iloc[:, 4:]                               \n\n#  Datetime Indexing\n# converting the date type to datetimes64\naqi_sb.date = pd.to_datetime(aqi_sb.date)    \n # updating the index to the data column                       \naqi_sb = aqi_sb.set_index('date')                                    \n\n# Rolling Window Mean Calc\n# provides rolling window calculations of \n# the mean aqi over 5 day periods  \naqi_sb['five_day_average'] = aqi_sb.aqi.rolling('5D').mean()         \n\n\n\n\nIs everything looking as we expect it to?\n\n\nCode\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# checking that dataframes joined properly and column names changed\nprint('The number of aqi observations in 2017 were:', len(aqi_17.Date))\nprint('The number of aqi observations in 2018 were:', len(aqi_18.Date))\nprint('The number of aqi observations between 2017-2018 were:', len(aqi.date))        \n\n\nThe number of aqi observations in 2017 were: 326801\nThe number of aqi observations in 2018 were: 327537\nThe number of aqi observations between 2017-2018 were: 654338\n\n\n\n\n\n\nThe visual below displays the mean AQI over a 5 day rolling window between January 2017 and October 2018. The background of the plot is color categorized according to the AQI’s six categories of concern for ppm levels. A relative trend of moderate is seen throughout the year. However,a spike in air pollutants between the months of December 2017 and January 2018 is clearly observed. The sharp initial peak observed the day the Thomas Fire began (Dec. 4, 2017) caused an inital AQI response within the Very Unhealthy category and over a 5 day period, averaged out into the Unhealthy category. This trend can be observed at the noted location in the figure below, indicating negative public health effects on air quality resulting from the Thomas Fire.\n\n\nCode\n#------------------------------------\n#  ----     Customization        ----\n#------------------------------------\n# Define AQI categories and colors\naqi_categories = {\n    'Good': (0, 50, '#00E400'),\n    'Moderate': (51, 100, '#FFFF00'),\n    'Unhealthy for Sensitive Groups': (101, 150, '#FF9933'),\n    'Unhealthy': (151, 200, '#FF0000'),\n    'Very Unhealthy': (201, 300, '#8B0000'),\n    'Hazardous': (301, 500, '#800080')\n}\n\ncolors = {'aqi':'#f69517',\n          'five_day_average':'#360F39'}\n\n\n#------------------------------------\n#  ----     Visualizing AQI      ----\n#------------------------------------\nfig, ax = plt.subplots(figsize=(12, 8))\n\n# Plot AQI categories as background colors for associated ranges\nfor category, (lower, upper, color) in aqi_categories.items():\n    ax.fill_between(aqi_sb.index, lower, upper, color=color,\n                    alpha=0.2,\n                    label=f'{category}')\n\n# Plot the AQI and 5-Day Rolling Average\naqi_sb.plot(ax=ax,\n            y=['aqi', 'five_day_average'],\n            color=colors,\n            xlabel='Date',                                                   \n            ylabel='AQI Values (ppm)',\n            ylim= (0,400),\n            legend= True\n            )\n\n# applying customizations\nax.set_title('Air Quality Index (AQI) Assessment of Santa Barbara County 2017-2018', \n             fontsize=18) \n\n# Add a legend for background colors\nbackground_legend = [Line2D([0], [0], color='#00E400', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FFFF00', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FF9933', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#FF0000', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#8B0000', lw=4, alpha=0.3),\n                     Line2D([0], [0], color='#800080', lw=4, alpha=0.3)]\n\n# Add background color legend to the plot\nbackground_legend_art = ax.legend(handles=background_legend,\n                                  labels=['Good', 'Moderate',\n                                          'Unhealthy for Sensitive Groups',\n                                          'Unhealthy', 'Very Unhealthy',\n                                          'Hazardous'],\n                                  loc='upper center',\n                                  bbox_to_anchor=(0.5, 1),\n                                  ncol=3,\n                                  fontsize = 12)\n# Line color legend\nline_legend = [Line2D([0], [0], color='#f69517', lw=2),\n               Line2D([0], [0], color='#360F39', lw=2)]\n\n# Add line color legend to the plot\nline_legend_art = ax.legend(handles=line_legend,\n                            labels=['AQI', '5-Day Average'],\n                            loc='upper right',\n                            bbox_to_anchor=(0.866, 0.88),\n                            fontsize = 12)\n\n# Add both legends to the plot\nax.add_artist(background_legend_art)\nax.add_artist(line_legend_art)\n\n# Add annotation\nax.annotate(\"* This peak is a result of the \\nThomas Fire in Santa Barbara.\", \n            xy=(0.45, 0.5), # position\n            xycoords='figure fraction', \n            fontsize=12, \n            color='black') \n\n# Adjust subplot parameters to add margin space\nplt.subplots_adjust(top=0.85, bottom=0.15, left=0.1, right=0.9)\n\nplt.show()\n\n\n\n\n\n\n\n\nLet’s get a full understanding of exactly how much local area was affected by the Thomas Fire by importing the fire perimeter boundary information & some super cool Landsat 2\n\n\n\n\nCode\n#------------------------------------\n# ----        Read  & Inspect     ----\n#------------------------------------\n# Reading in the data for CA fire perimeters \nca_fire = gpd.read_file(os.path.join(os.getcwd(),'..','data','California_Fire_Perimeters_1379327890478655659','California_Fire_Perimeters_(all).shp'))\n\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# Suppress warnings\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning) \n\n# Create a figure with two subplots\nfig, ax = plt.subplots(1, 2, figsize=(14, 7))\n\n# quick viuslaization of CA fire perimeters\n# yow-za! CA is so clearly shaped }:&lt;\nca_fire.plot(ax = ax[0],\n             color = '#AA4203')\nax[0].set_title('CA Fire Perimeters')\n\n\n# Subset for Thomas Fire boundary data for plotting\nthomas_fire = ca_fire.loc[(ca_fire['FIRE_NAME'] == 'THOMAS') & (ca_fire['YEAR_'] &gt;= 2017)]          \n\n\nthomas_fire.plot(ax = ax[1],\n                 color = '#AA4203')\nax[1].set_title('Thomas Fire Boundary')\n\n# Adjust layout to prevent overlap\nplt.tight_layout()\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\nTogether, we’re going to load in Landsat data directly from the Microsoft Planetary Computer STAC and collect our desired bands (SWIR22, NIR08, Red) to create a landsat array subset.LE07_L2SP_042036_20171217_02_T1 was captured on 12/17/2017 18:36:51 UTC and will be leveraged for this project.\nIn order to create a false color image, we need to adjust the dimensions of our data to only consider x and y coordinates. Furthermore, we will need to create an array containing the false color bands we intend on utilizing for our ROI. We’ll also be correcting the CRS so we can overlay the two datasets.\n\n\nCode\n#--------------------------------------\n# ---- Pull directly from MPC STAC ----\n#--------------------------------------\n# Suppress warnings\nwarnings.filterwarnings('ignore', category=DeprecationWarning)  # Suppress FutureWarnings\n\n\n# Let's pull our data fresh from the MPC STAC\n# We're also going to assign the bands we're interested in\nitem_url = \"https://planetarycomputer.microsoft.com/api/stac/v1/collections/landsat-c2-l2/items/LE07_L2SP_042036_20171217_02_T1\"\n\n# Load the individual item metadata and sign the assets\nitem = pystac.Item.from_file(item_url)\nsigned_item = planetary_computer.sign(item)\n\n#--------------------------------------\n# ----   Collect band information  ----\n#--------------------------------------\n# Open the desired data assets\n# Short Wave Infrared (SWIR22) band\nasset_href_swir22 = signed_item.assets[\"swir22\"].href\nlandsat_swir22 = rioxr.open_rasterio(asset_href_swir22)\n\n# Near Infrared (NIR08) band\nasset_href_nir08 = signed_item.assets[\"nir08\"].href\nlandsat_nir08 = rioxr.open_rasterio(asset_href_nir08)\n\n# Red band\nasset_href_red = signed_item.assets[\"red\"].href\nlandsat_red = rioxr.open_rasterio(asset_href_red)\n\n# Green band\nasset_href_green = signed_item.assets[\"green\"].href\nlandsat_green = rioxr.open_rasterio(asset_href_green)\n\n# Blue band\nasset_href_blue = signed_item.assets[\"blue\"].href\nlandsat_blue = rioxr.open_rasterio(asset_href_blue)\n\n#--------------------------------------\n#  ----  Combine band information  ---- \n#--------------------------------------\n#--------------------------------------\n#  ----         True Color         ---- \n#--------------------------------------\n# Stack bands into a single dataset\ntrue_color = xr.concat([landsat_red, landsat_green, landsat_blue], dim='band')\n\n# Updating data for plotting\n# Original dimensions and coordinates show us that band is a dimension\n# Remove length 1 dimension (band)\ntrue_color = true_color.squeeze()\n\n# remove coordinates associated to band\ntrue_color = true_color.drop('band')\n\n#--------------------------------------\n#  ----        False Color         ---- \n#--------------------------------------\n# Note: For false-color, typically, you might use \n# a different combination (like NIR, Red, Green).\n# Adjust this based on the specific visualization you want.\nfalse_color = xr.concat([landsat_swir22, landsat_nir08, landsat_red], dim='band')\n\n# Updating data for plotting\n# Original dimensions and coordinates show us that band is a dimension\n# Remove length 1 dimension (band)\nfalse_color = false_color.squeeze()\n\n# remove coordinates associated to band\nfalse_color = false_color.drop('band')\n\n#--------------------------------------\n#  ---- Visualize band information ---- \n#--------------------------------------\n# Create a figure with two subplots\nfig, ax = plt.subplots(1, 2, figsize=(14, 7))\n\n# Plot the true and false color images\n#--------------------------------------\n#  ----     True Color Image       ---- \n#--------------------------------------\n# Plot the false color image\ntrue_color.plot.imshow(ax=ax[0],\n                        robust=True) \nax[0].set_title('True Color Landsat Image (Red, Green, Blue)')\n\n\n#--------------------------------------\n#          False Color Image\n#--------------------------------------\nfalse_color.plot.imshow(ax=ax[1],\n                        robust=True)\nax[1].set_title('False Color Landsat Image (SWIR22, NIR08, Red)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\nIt looks good, let’s take a quick peak at the geospatial attr\n\n\nCode\n#------------------------------------\n# ----        Check Point!       ----\n#------------------------------------\n# Check geospatial attributes\nprint('height: ', false_color.rio.height)\nprint('width: ', false_color.rio.width, '\\n')\nprint(false_color.rio.bounds(), '\\n')\n\n# Now to update the CRS to match and check\n# Convert DataFrame to GeoDataFrame\nthomas_fire  = gpd.GeoDataFrame(thomas_fire, geometry='geometry')\n\nthomas_fire = thomas_fire.to_crs(false_color.rio.crs)                                      \n\n# Print CRS to check alignment\nprint('Thomas Fire Boundary CRS: ', thomas_fire.crs)\nprint('False Color CRS: ', false_color.rio.crs)\n\n\nheight:  7271\nwidth:  8291 \n\n(106785.0, 3725685.0, 355515.0, 3943815.0) \n\nThomas Fire Boundary CRS:  PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\nFalse Color CRS:  EPSG:32611"
  },
  {
    "objectID": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html#inspecting-areas-burned-by-thomas-fire-in-santa-barbara-county-2017",
    "href": "posts/2023-11-13-ThomasFire/AQI_False_Color_Img.html#inspecting-areas-burned-by-thomas-fire-in-santa-barbara-county-2017",
    "title": "Investigation on the Thomas Fire Impacts in Santa Barbara County, CA (2017 - 2018)",
    "section": "Inspecting Areas Burned by Thomas Fire in Santa Barbara County (2017)",
    "text": "Inspecting Areas Burned by Thomas Fire in Santa Barbara County (2017)\nBelow, we’ve overlayed the fire perimeter boundaries for the Thomas Fire over it’s respective burn scar. Our false color image displays an outline of the fire scorn area of Santa Barbara County. Here, we can observe the severity of the damage by generally visualizing the area and the types of regions impacted by the wildfire.\n\n\nCode\n#------------------------------------\n# ----  Plot Landsat False Color ----\n#------------------------------------\n# Adjust the figure size and DPI\nfig, ax = plt.subplots(figsize=(6, 6)) \n\n# Plot false color bands\nfalse_color.plot.imshow(ax=ax, robust=True)\n\n# Plot Thomas Fire burn area\nthomas_fire.plot(ax=ax, color='none', edgecolor='#AA4203')\n\n# Add a legend for the burned area\nfire_scar = mpatches.Patch(color='#AA4203', label='Burned Area')\nax.legend(handles=[fire_scar], loc='upper right', fontsize=12) \n\n# Add a title to the plot\nax.set_title('False Color Image (SWIR22, NIR08, Red)', fontsize=14)  \n\n# Remove the plot axes\nax.axis('off')\n\n# Save the figure with tight bounding box and high resolution\nplt.savefig('thomas_fire_plot.png')  \nplt.show()\n\n\n\n\n\n\nCombining the Visuals\nLet’s put the most informative visuals together into a single figure to gain a full sense of the extent of damage caused by the Thomas Fire. In AQI the figure on the left, there is a sharp peak observed the day the Thomas Fire began (Dec. 4, 2017) that fell within the Very Unhealthy category and over a 5 day period, averaged out into the Unhealthy category. This trend can be observed at the noted location in the figure below, indicating negative public health effects on air quality resulting from the Thomas Fire. The figure on the right, displays the large parcel of Santa Barbara County that was engulfed by the fire, explaining the uptake in particulate matter observed in December of 2017. There were significant direct impacts on public health in terms of air quality as a response to this fire and this can be understood when considering the size of the burn scar seen in the figure on the right.\n\n\nCode\n#------------------------------------\n#  ----     Customization        ----\n#------------------------------------\n# Define AQI categories and colors\naqi_categories = {\n    'Good': (0, 50, '#00E400'),\n    'Moderate': (51, 100, '#FFFF00'),\n    'Unhealthy for Sensitive Groups': (101, 150, '#FF9933'),\n    'Unhealthy': (151, 200, '#FF0000'),\n    'Very Unhealthy': (201, 300, '#8B0000'),\n    'Hazardous': (301, 500, '#800080')\n}\n\ncolors = {'aqi':'#f69517',\n          'five_day_average':'#360F39'}\n\n# Plot the images in the same figure side-by-side\nfig, (ax1, ax2) = plt.subplots(1, 2, \n                               figsize = (22,8)) \n\n\n#------------------------------------------------------------------------\n# Plotting the Daily & 5-Day Rolling Window AQI for Santa Barbara County \n#------------------------------------------------------------------------\n#------------------------------------\n#  ----     Visualizing AQI      ----\n#------------------------------------\n# Plot AQI categories as background colors for associated ranges\nfor category, (lower, upper, color) in aqi_categories.items():\n    ax1.fill_between(aqi_sb.index, lower, upper, color=color, alpha=0.2, label=f'{category}')\n\n# Plot the AQI and 5-Day Rolling Average\naqi_sb.plot(ax=ax1,\n            y=['aqi', 'five_day_average'],\n            color=colors,             \n            ylim= (0,400),\n            legend= True,\n            ylabel='AQI Values (ppm)'\n            )\n\n# applying customizations\nax1.set_title('Air Quality Index (AQI) Assessment of Santa Barbara County 2017-2018', \n             fontsize=21) \n\nax1.set_xlabel(xlabel='Date',\n               fontsize = 13)\n\nax2.set_ylabel(ylabel='AQI Values (ppm)',\n               fontsize = 10)\n\n# Add a legend for background colors\nbackground_legend = [Line2D([0], [0], color='#00E400', lw=6, alpha=0.3),\n                     Line2D([0], [0], color='#FFFF00', lw=6, alpha=0.3),\n                     Line2D([0], [0], color='#FF9933', lw=6, alpha=0.3),\n                     Line2D([0], [0], color='#FF0000', lw=6, alpha=0.3),\n                     Line2D([0], [0], color='#8B0000', lw=6, alpha=0.3),\n                     Line2D([0], [0], color='#800080', lw=6, alpha=0.3)]\n\n# Add background color legend to the plot\nbackground_legend_art = ax1.legend(handles=background_legend,\n                                  labels=['Good', 'Moderate', \n                                          'Unhealthy for Sensitive Groups'\n                                          'Unhealthy', 'Very Unhealthy',\n                                          'Hazardous'],\n                                  loc='upper center',\n                                  bbox_to_anchor=(0.5, 1),\n                                  ncol=3,\n                                  fontsize = 18)\n# Line color legend\nline_legend = [Line2D([0], [0], color='#f69517', lw=2),\n               Line2D([0], [0], color='#360F39', lw=2)]\n\n# Add line color legend to the plot\nline_legend_art = ax1.legend(handles=line_legend,\n                            labels=['AQI', '5-Day Average'],\n                            loc='upper right',\n                            bbox_to_anchor=(1, 0.86),\n                            fontsize = 18)\n\n# Add both legends to the plot\nax1.add_artist(background_legend_art)\nax1.add_artist(line_legend_art)\n\n# Add annotation\nax1.annotate(\"* This peak is a result of the \\nThomas Fire in Santa Barbara.\", \n            xy=(0.28, 0.52), # position\n            xycoords='figure fraction', \n            fontsize=20, \n            color='black') \n#------------------------------------------------------------------------\n#        Plotting the Thomas Fire burned areas of Santa Barbara\n#------------------------------------------------------------------------\n # Remove plot axes\nplt.axis('off')                               \n# Plot false color bands\nfalse_color.plot.imshow(ax = ax2,              \n                        # Include colors\n                        robust = True)        \n\n# Plot thomas fire burn area\nthomas_fire.plot(ax = ax2,                     \n       # No color of burn area\n       color = 'none',                         \n       # Opacity of edgecolor\n       edgecolor = '#AA4203')     \n          \n# Add a figure legend\nfire_scar = mpatches.Patch(color = '#AA4203',\n                          label = 'Burned Area') \n\nax2.legend(handles=[fire_scar])\n\n#------------------------------------\n# ----   Plot the Fire Bound    -----\n#------------------------------------\nthomas_fire.plot(ax = ax2,\n                 color = '#AA4203',\n                 # make border around shapefile\n                edgecolor = '#AA4203', \n                 # make transparent\n                alpha = 0.5)\n\nfire_patch = mpatches.Patch(color = '#AA4203',\n                            label = \"Thomas Fire\")\n\n#------------------------------------\n# ----  Plot Landsat False Color ----\n#------------------------------------\n# Plot the false landsat\nfalse_color.plot.imshow(ax = ax2,\n                          robust = True) \n\n# Edit the Legend and Caption \n# Show lables for legend\nax2.legend(handles = [fire_patch], \n        # No border around legend\n          frameon = True,\n        # Where legend is located\n          bbox_to_anchor = (0.9, 0.8),\n          fontsize = 18) \n \n# Add title\nax2.set_title('Areas Burned by Thomas Fire in Santa Barbara, CA (2017)',\n               fontsize = 21) \n\n# Plot the whole figure  \n# space well\nfig.tight_layout()\nplt.show()\n\n\n\n\n\n\nCitations:\n\nWikipedia contributors. “Thomas Fire.” Wikipedia, The Free Encyclopedia. Wikipedia, The Free Encyclopedia, 16 Apr. 2024. Web. 2 Aug. 2024.\nVCFD determines cause of The thomas fire. Ventura County Fire Department. (2019, March 13). https://vcfd.org/news/vcfd-determines-cause-of-the-thomas-fire/\nWildfire Today. “Thomas Fire Archives - Wildfire Today.” Wildfire Today, 14 Nov. 2019, https://wildfiretoday.com/tag/thomas-fire.\nCalifornia, State Of. Montecito Mudslides Anniversary, Reflections Through Images | Cal OES News. https://news.caloes.ca.gov/montecito-mudslides-anniversary-reflections-through-images.\nAirNow.gov, U.S. EPA. (n.d.). Aqi Basics. AQI Basics | AirNow.gov. https://www.airnow.gov/aqi/aqi-basics/\nMicrosoft Planetary Computer. Planetary Computer. (n.d.). https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2\nCalifornia fire perimeters (all). California State Geoportal. (n.d.). https://gis.data.ca.gov/datasets/CALFIRE-Forestry::california-fire-perimeters-all-1/about"
  },
  {
    "objectID": "posts/2023-10-08-AffordableHousing/AffordableHousing.html",
    "href": "posts/2023-10-08-AffordableHousing/AffordableHousing.html",
    "title": "Addressing the Critical Barriers When Developing Affordable Housing: Solutions to Improve the Current Approach to Address the Housing Crisis.",
    "section": "",
    "text": "A third of renters and homeowners across the country are experiencing housing related cost burdens. In 2021, 21.6 million households experienced cost burdens, with over half of them spending more than 50% of their income on housing. For homeowners, 19 million homeowners were cost burdened, with 8.7 million spending over 50% of their paychecks on housing costs (Habitat for Humanity). As the cost of housing rises, it displaces people from their homes and communities, and in many cases pushes them farther into the margins society. Away from economic centers, life becomes more expensive and time becomes a precious resource that is slowly being consumed by commute times.\nThis problem isn’t new. City governments have invested in affordable housing - but seemingly without consideration of what the purpose or opportunity they provided. Other attempts at building affordable housing have produced disastrous results. These government failures have deincentivized them from investing in new ways to provide affordable housing. Many solutions that are currently applied don’t incorporate the concept that affordable housing should be a tool for increasing stability and social mobility that can grant people autonomy and change the future.\nAnother issue is that there is a long term trend of diminishing supply for low-income needs. There are only 7 million affordable units for 11 million households with extremely low incomes; low income households are defined as “at or below either the federal poverty guideline or 30% of the area median income”(Housing Matters). Forcing millions of individuals to experience cost burden because of a lack of availability of affordable housing."
  },
  {
    "objectID": "posts/2023-10-08-AffordableHousing/AffordableHousing.html#data-science-in-affordable-housing",
    "href": "posts/2023-10-08-AffordableHousing/AffordableHousing.html#data-science-in-affordable-housing",
    "title": "Addressing the Critical Barriers When Developing Affordable Housing: Solutions to Improve the Current Approach to Address the Housing Crisis.",
    "section": "Data Science in Affordable Housing",
    "text": "Data Science in Affordable Housing\n\nData in Development\nThere are many things that can make the building of affordable housing an easy option.\n\nMaking the information available for use and implementation\n\nCompile a list / map of available plots that the city owns and the zoning options for those plots\nFor each area of land available for development:\n\nPresent 2 options:\n\nNormal development: Present the proposed zoning and floor area (FAR)\nAffordable housing development: Present the proposed up-zoning and floor area (FAR)\n\nAllow developers to compare options and make it easy for those that are interested in developing quality affordable housing.\n\n\n\n\nDeveloping Research Tools\nQuestions to consider:\n\nWhat is the goal?\n\nWhat are you trying to reveal with your analysis? Who are you trying to help?\n\nWho is defining the goal?\n\nHave you talked to members of the community that are affected by this scrutiny/observation?\nHave you made their voices central to defining the problem and listened to proposed solutions?\n\nWhat assumptions are you making about the community?\nWhat factors are you considering to be important?\n\nWhat data are you using to determine location/accessibility?\nAre you selecting the right variables in your understanding?\nHow did you choose those variables/indicators?\n\n\n\nFigure 6: The AVE (Activate, Visit, Experience) was created in Viriginia Beach, Virginia to increase mobility access and is a part of a larger holistic community revitalization project (U.S. Dept. of Housing & Urban Development).\n\n\n\nOrganizations conducting data collection and analysis on affordable housing\n\n\n\nHousing Assessment Resources Tools (HART)\n\nLearn more here\nHousing assessment tool: Measures core housing needs and affordable housing costs by income category, household size, and vulnerable populations.\nLand assessment tool: looks at the area in Toronto that could be developed and measures its proximity to important amenities. Makes recommendations for building affordable housing in those areas because they already have access to the amenities that they would need.\nProperty acquisition tool: acquisition of existing housing to maintain access to affordable housing supply over the long term, and develop resources to aid governments at all levels to implement effective acquisition strategies.\n\n\nOther and Belonging Institute\n\n\nLearn more here\nThis institute at Berkeley works on understanding marginalization and exclusion. They have published research on the benefits of community land trusts as stewards of public land. Provide a guide for how local governments can partner with community land trusts to achieve their goals.\nHow does a Community Land Trust work:\n\nUse ground lease that ensures permanent affordability and community control to provide lower income community members.\nSupport residents with services that ensure their financial stability and ability to thrive.\nCities can donate surplus land to CLT’s to support communities.\n\n\n\nParkdale Neighborhood land trust\nLearn more here\nNon-profit that owns and manages land in a community ownership model, and partners with housing partners who then provide high quality affordable housing, supportive housing, and community economic development programs.\n\n\nTapestry\n\nLearn more here\nInvestment marketplace that finances community projects as a form of impact investing. Help nonprofits and cooperatives raise funds for their projects through a network of investors and buying bonds.\n\n\nCommunity Ethics Research Workshop (CREW)\nLearn more here\n“We want to develop a community review model that empowers community members to review and offer suggestions on research proposals in collaboration with researchers. Ultimately, we want to work towards reducing the harms associated with research and making it easier for researchers to collaborate in our community in a positive, respectful way.”\n\n\nBalanced Supply of Housing Research Cluster (BSHRC)\nLearn more here\nLooking at four major Canadian city regions to understand the attitudes on neighborhood densification for affordability, choice, and diversity."
  },
  {
    "objectID": "posts/2023-10-08-AffordableHousing/AffordableHousing.html#providing-security-beyond-housing",
    "href": "posts/2023-10-08-AffordableHousing/AffordableHousing.html#providing-security-beyond-housing",
    "title": "Addressing the Critical Barriers When Developing Affordable Housing: Solutions to Improve the Current Approach to Address the Housing Crisis.",
    "section": "Providing Security Beyond Housing",
    "text": "Providing Security Beyond Housing\nTo provide true housing security to individuals, we need policies to protect our people and work to create vocational schools, mentorship programs, and/or apprenticeship opportunities to help residents find career paths and gain access to high quality local jobs. This can be achieved by partnering with existing local job providers, educational institutions, and public agencies to train community members to enter the job market, obtain high-quality work, and earn a comfortable wage. In order to build a stronger economy, it is essential that the community has a wide range of opportunities and resources available. Strengthening Community Involvement\nCommunity members carry a wealth of insights to help solve local community issues like affordable housing. Working with a wide range of local individuals who represent community groups, industries, and institutions, to leverage the wisdom of active partners in our community will assist in the facilitation of access to fair housing, clean water, air, and green spaces.\nFurthermore, community members need to be notified far in advance when there is talk of a significant local project. The community members should not be forced to rely on a last minute notice as a means to voice their concerns. A trend within research findings demonstrates lower rates of residential displacement when early community collaboration is practiced in the planning process (National Low Income Housing Coalition). Incorporating the community in the planning process not only helps protect low-income or existing residents from displacement and aids in the removal of developer’s ambiguity as they navigate an uncertain planning process. Overall, fostering more support for projects. Ways to Include the Community Working with local residents to research and peer-review housing policies in other areas, and most importantly. Providing an opportunity for early feedback on planning issues that are occurring within the community. Community development staff attend community meetings frequently to allow for more collaborative solutions to issues such as: affordable housing, traffic, overlay zones, density, etc. Organizing with a local educational institution to offer architectural students an opportunity to design housing projects.\n\nReferences\n\n“2023 State of the Nation’s Housing Report: 4 Key Takeaways.” Cost of Home, www.habitat.org/costofhome/2023-state-nations-housing-report-lack-affordable-housing#:~:text=During%20the%20pandemic%2C%20the%20number,that%20exceeded%20half%20their%20income. Accessed 11 Dec. 2023.\n“Addressing America’s Affordable Housing Crisis.” Housing Matters, 12 Apr. 2023, housingmatters.urban.org/research-summary/addressing-americas-affordable-housing-crisis.\n“Gentrification and Neighborhood Revitalization: What’s the Difference?” National Low Income Housing Coalition, 5 Apr. 2019, nlihc.org/resource/gentrification-and-neighborhood-revitalization-whats-difference.\nHelen Eloyan, www.heleneloyan.com/. Accessed 11 Dec. 2023.\nRyan Jones June 24, 2022. ” Michigan Law Journal of Law and Mobility.” 24 June 2022, futurist.law.umich.edu/potential-solutions-to-the-first-mile-last-mile-problem/#:~:text=One%20of%20these%20challenges%2C%20known,transportation%20station%20to%20their%20destination.\nDevelopment, U. S. Dept. Of Housing and Urban. “U.S. Dept. Of Housing And Urban Development (HUD).” Flickr, www.flickr.com/photos/hudopa.\n“171 New 100% Affordable Homes Arrive in the South Bronx.” The Official Website of the City of New York, 28 Oct. 2024, www.nyc.gov/site/hpd/news/044-24/171-new-100-affordable-homes-arrive-the-south-bronx#/0.\n“General  2 — City of Ventura General Plan.” City of Ventura General Plan, www.planventura.com/background-documents."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Professionally\nI’m known as a creative strategist, an analytics enthusiast, and a certified chemist in-and-out of the kitchen. I am a recent graduate student interested in strategizing climate and global resilience solutions utilizing GIS techniques. After finishing my undergraduate degree in Chemistry, I moved to Santa Barbara in 2023 to further my education and develop my career path by earning a Master’s in Environmental Data Science with the Bren School of Environmental Science & Management, UCSB. At the outset of the program, I also began a student research assistantship with The 2035 Initiative at UCSB. Throughout my assistantship, I gained experience in using various GIS techniques and softwares; troubleshooting and debugging; using HPC environments; and routinely reporting updates to diverse interdisciplinary teams.\nI hope to continue participating in projects that elicit real change, propelling me forward in my career trajectory. At this early stage in my career, I intend to focus my experience as a data scientist on writing policy suggestions for sustainability and resiliency related issues. I am most interested in research related to preparation for extreme climate events, the clean energy transition, assessing public health exposure to pollutants after hazardous events, and resource management.\n\n\n\n\n\n\n\n\nMEDS Class of 2024 the day of our Capstone Public Presentation! Date: May 2024.\n\n\n\n Behind the Screen\nIn case you were curious about my name pronunciation, (“Sof-aya” like papaya), it’s actually a piece of my family’s history. See, my mom’s ancestors immigrated from Trondheim, Norway and carried a tradition of namesakes. Unlike the typical Jr., Sr., The III, our family skips every other generation. For example, I’m named after my beloved grandmother, Sofia Anne. This tradition’s been in our family for eight generations! Growing up, I didn’t always love having a unique pronunciation, but it’s given me the confidence to speak up and politely correct someone. I love my name, the strength it gives me, and my lineage tied to it.\n\n\n\n\n\n\n\n\nThis is my lovely grandmother, whom I was named after, Sofia Anne. In this photo, we were out enjoying brunch at this tasty place called Madison on Park in San Diego. Date: June 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "scratch/Resources.html",
    "href": "scratch/Resources.html",
    "title": "All of my favorite resources",
    "section": "",
    "text": "Back to top"
  }
]